        "randomPolicy": {
            "batchSize": 0,
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100  1702  100  1702    0     0  72931      0 --:--:-- --:--:-- --:--:-- 74000
            "numBatches": 0
        },
        "enableActivePolicyChurn": false,
        "enableAppLayerPolicy": false
    }
}
=== Scaling Services to 3000 ===
Current service count: 2999
Target service count: 3000
Adding 1 services...
+ NUM_TO_ACTION=1
+ THREADS=10
+ ACTION=apply
++ kubectl get svc -A
++ grep test-svc
++ wc -l
+ NUM=2999
+ '[' apply == delete ']'
+ '[' apply == apply ']'
+ seq 2999 2999
+ xargs -P 10 -I _ sh -c 'sed '\''s/9999/_/'\'' /scripts/example.yaml | kubectl apply -f -'
service/test-svc-2999 created
/apps
Final service count: 3000
pod "loadgenerator-59d7b7cc48-5lf8m" deleted
pod "prometheus-push-gateway-4vgf2" deleted
pod "prometheus-push-gateway-7hfz8" deleted
pod "prometheus-push-gateway-gfzdw" deleted
pod "prometheus-client-0" deleted
Calling start endpoint...
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
Started test. 
{
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100  1679  100  1679    0     0  80154      0 --:--:-- --:--:-- --:--:-- 83950
    "prefix": "cali",
    "numNamespaces": 1,
    "podsPerClient": 8,
    "numClientDeployments": 8,
    "numServerDeployments": 2,
    "podsPerServer": 4,
    "tearDown": false,
    "disableCrossNamespace": false,
    "crossNamespaceOnly": false,
    "clients": {
        "nodeSelector": {
            "cloud.google.com/gke-nodepool": "default-pool"
        },
        "tolerations": null,
        "image": "gcr.io/unique-caldron-775/ttfp:v0.12.0",
        "imagePullPolicy": "IfNotPresent",
        "maxUnavailable": 1,
        "numChurns": 999999999,
        "churnTimeout": 3600000000000,
        "protocol": "tcp",
        "timeout": "",
        "url_length_factor": "",
        "connectionsPerSecond": 10,
        "expectFailConnectionsPerSecond": 10,
        "resources": {
            "requests": {
                "cpu": "10m"
            }
        }
    },
    "servers": {
        "nodeSelector": {
            "cloud.google.com/gke-nodepool": "default-pool"
        },
        "tolerations": null,
        "image": "nginx:1.19.6",
        "imagePullPolicy": "IfNotPresent",
        "maxUnavailable": 1,
        "numChurns": 999999999,
        "churnTimeout": 3600000000000,
        "resources": {
            "requests": {
                "cpu": "10m"
            }
        },
        "readinessProbe": {
            "httpGet": {
                "path": "/",
                "port": 80,
                "scheme": "HTTP"
            }
        }
    },
    "policies": {
        "randomPolicy": {
            "batchSize": 0,
            "numBatches": 0
        },
        "enableActivePolicyChurn": false,
        "enableAppLayerPolicy": false
    }
}
Attempt 1 of 5 to get TTFP 99th percentile TTFP_VALUE...
TTFP 99th percentile: 2.771227775700001
SUCCESS: TTFP startup time is within the acceptable range (2.771227775700001 seconds)
=== Recording calico-node startup time ===
=== Calico Node Startup Time Measurement ===
Namespace: calico-system
Label Selector: k8s-app=calico-node
Target Node: glen-bz-iir5-kadm-node-0.us-central1-a.c.tigera-dev.internal
Acceptable Startup Time: 60s

=== Collecting Cluster Information ===
Kubernetes Version: v1.33.5

=== Calico Configuration ===
Dataplane Mode: Nftables
Encapsulation Type: IPIP
BGP Enabled: Enabled
IP Pool CIDR: 192.168.0.0/16

=== Cluster Scale Metrics ===
Total NetworkPolicies: 2017
Total Services: 3049
Total Ready Nodes: 504

=== Tigera Status ===

Shortened Tigera Status:
NAME                          AVAILABLE   PROGRESSING   DEGRADED   SINCE
apiserver                     True        False         False      3h11m
calico                        True        False         False      6m47s
intrusion-detection           True        False         False      3h8m
ippools                       True        False         False      3h11m
log-collector                 True        False         False      3h10m
log-storage                   True        False         False      3h11m
log-storage-access            True        False         False      3h7m
log-storage-dashboards        True        False         False      3h8m
log-storage-elastic           True        False         False      3h8m
log-storage-esmetrics         True        False         False      3h8m
log-storage-kubecontrollers   True        False         False      3h8m
log-storage-secrets           True        False         False      3h11m
manager                       True        False         False      3h9m
monitor                       True        False         False      3h11m
policy-recommendation         True        False         False      3h11m
tiers                         True        False         False      3h11m

Full Tigera Status (YAML):
      message: All objects available
      observedGeneration: 1
      reason: AllObjectsAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-10-28T17:55:10Z"
      message: All Objects Available
      observedGeneration: 1
      reason: AllObjectsAvailable
      status: "False"
      type: Progressing
- apiVersion: operator.tigera.io/v1
  kind: TigeraStatus
  metadata:
    creationTimestamp: "2025-10-28T17:52:55Z"
    generation: 1
    name: monitor
    resourceVersion: "5065"
    uid: aeb0d306-9a5f-402b-80a1-a0851025ae7c
  spec: {}
  status:
    conditions:
    - lastTransitionTime: "2025-10-28T17:53:40Z"
      message: All Objects Available
      observedGeneration: 1
      reason: AllObjectsAvailable
      status: "False"
      type: Degraded
    - lastTransitionTime: "2025-10-28T17:53:40Z"
      message: All objects available
      observedGeneration: 1
      reason: AllObjectsAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-10-28T17:53:40Z"
      message: All Objects Available
      observedGeneration: 1
      reason: AllObjectsAvailable
      status: "False"
      type: Progressing
- apiVersion: operator.tigera.io/v1
  kind: TigeraStatus
  metadata:
    creationTimestamp: "2025-10-28T17:52:55Z"
    generation: 1
    name: policy-recommendation
    resourceVersion: "5636"
    uid: b06e0bd2-24eb-4abe-ad4f-4aa19f11916f
  spec: {}
  status:
    conditions:
    - lastTransitionTime: "2025-10-28T17:53:50Z"
      message: All Objects Available
      observedGeneration: 1
      reason: AllObjectsAvailable
      status: "False"
      type: Degraded
    - lastTransitionTime: "2025-10-28T17:53:50Z"
      message: All objects available
      observedGeneration: 1
      reason: AllObjectsAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-10-28T17:53:50Z"
      message: All Objects Available
      observedGeneration: 1
      reason: AllObjectsAvailable
      status: "False"
      type: Progressing
- apiVersion: operator.tigera.io/v1
  kind: TigeraStatus
  metadata:
    creationTimestamp: "2025-10-28T17:52:55Z"
    generation: 1
    name: tiers
    resourceVersion: "5637"
    uid: c3ee6bbe-357f-4971-b333-5ac821f2bc5e
  spec: {}
  status:
    conditions:
    - lastTransitionTime: "2025-10-28T17:53:50Z"
      message: All Objects Available
      reason: AllObjectsAvailable
      status: "False"
      type: Degraded
    - lastTransitionTime: "2025-10-28T17:53:50Z"
      message: All objects available
      reason: AllObjectsAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-10-28T17:53:50Z"
      message: All Objects Available
      reason: AllObjectsAvailable
      status: "False"
      type: Progressing
kind: List
metadata:
  resourceVersion: ""

=== Starting Calico Node Restart Test ===
Found pod: calico-node-d48nf on node glen-bz-iir5-kadm-node-0.us-central1-a.c.tigera-dev.internal
Deleting pod calico-node-d48nf...
pod "calico-node-d48nf" deleted
Waiting for new pod on node glen-bz-iir5-kadm-node-0.us-central1-a.c.tigera-dev.internal...
New pod detected: calico-node-tm9qw
Pod created at: 2025-10-28T21:05:05Z (epoch: 1761685505)
Waiting for pod calico-node-tm9qw to become Ready...
      status: "False"
      type: Progressing
- apiVersion: operator.tigera.io/v1
  kind: TigeraStatus
  metadata:
    creationTimestamp: "2025-10-28T17:52:55Z"
    generation: 1
    name: policy-recommendation
    resourceVersion: "5636"
    uid: b06e0bd2-24eb-4abe-ad4f-4aa19f11916f
  spec: {}
  status:
    conditions:
    - lastTransitionTime: "2025-10-28T17:53:50Z"
      message: All Objects Available
      observedGeneration: 1
      reason: AllObjectsAvailable
      status: "False"
      type: Degraded
    - lastTransitionTime: "2025-10-28T17:53:50Z"
      message: All objects available
      observedGeneration: 1
      reason: AllObjectsAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-10-28T17:53:50Z"
      message: All Objects Available
      observedGeneration: 1
      reason: AllObjectsAvailable
      status: "False"
      type: Progressing
- apiVersion: operator.tigera.io/v1
  kind: TigeraStatus
  metadata:
    creationTimestamp: "2025-10-28T17:52:55Z"
    generation: 1
    name: tiers
    resourceVersion: "5637"
    uid: c3ee6bbe-357f-4971-b333-5ac821f2bc5e
  spec: {}
  status:
    conditions:
    - lastTransitionTime: "2025-10-28T17:53:50Z"
      message: All Objects Available
      reason: AllObjectsAvailable
      status: "False"
      type: Degraded
    - lastTransitionTime: "2025-10-28T17:53:50Z"
      message: All objects available
      reason: AllObjectsAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-10-28T17:53:50Z"
      message: All Objects Available
      reason: AllObjectsAvailable
      status: "False"
      type: Progressing
kind: List
metadata:
  resourceVersion: ""

=== Starting Calico Node Restart Test ===
Found pod: calico-node-d48nf on node glen-bz-iir5-kadm-node-0.us-central1-a.c.tigera-dev.internal
Deleting pod calico-node-d48nf...
pod "calico-node-d48nf" deleted
Waiting for new pod on node glen-bz-iir5-kadm-node-0.us-central1-a.c.tigera-dev.internal...
New pod detected: calico-node-tm9qw
Pod created at: 2025-10-28T21:05:05Z (epoch: 1761685505)
Waiting for pod calico-node-tm9qw to become Ready...
pod/calico-node-tm9qw condition met

========================================
DaemonSet pod calico-node-tm9qw became Ready in 36 seconds.
Calico-node startup time: 36s
========================================

========================================
CALICO NODE STARTUP TEST RESULTS
========================================
Cluster Information:
  Kubernetes Version: v1.33.5
  Total Ready Nodes: 504

Calico Configuration:
  Dataplane Mode: Nftables
  Encapsulation: IPIP
  BGP Enabled: Enabled

Cluster Scale:
  Total NetworkPolicies: 2017
  Total Services: 3049

Performance:
  Calico-node startup time: 36s
========================================

✅ SUCCESS: calico-node-tm9qw startup time is within the acceptable range (36 seconds < 60s)
=== Calico-node startup time recorded successfully ===
=== End Results ===

All TTFP tests completed successfully!
Stream closed EOF for default/scale-platform-provider-ttfp-test-run-4k-services-jr5qk (tester)
